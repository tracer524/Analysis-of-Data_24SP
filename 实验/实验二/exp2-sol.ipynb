{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "from urllib.request import urlopen\n",
    "html = urlopen('https://dblp.uni-trier.de/db/conf/kdd/kdd2023.html')\n",
    "html_text = bytes.decode(html.read())\n",
    "with open('page.txt', 'w', encoding='UTF-8') as file:\n",
    "    file.write(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "def extract(text):\n",
    "    pieces = text.split('>')\n",
    "    if len(pieces) == 1 and len(pieces[0].split('<')) == 1:\n",
    "        return text\n",
    "    if len(pieces[0].split('<')) < 2:\n",
    "        pieces[0] = '<' + pieces[0]\n",
    "    pieces = [piece.split('<')[0] for piece in pieces]\n",
    "    output = ''.join(pieces)\n",
    "    return output\n",
    "\n",
    "track_part = html_text.split('<header class=\"h2\">')[1:]\n",
    "track_name_text = [part.split(\"</h2>\")[0] for part in track_part]\n",
    "track_name = [extract(name_text) for name_text in track_name_text]\n",
    "track_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "def sep_paper(text):\n",
    "    author_info, title_info = text.split('<span class=\"title\" itemprop=\"name\">')\n",
    "    title_info, pages_info = title_info.split('<span itemprop=\"pagination\">')\n",
    "    authors = extract(author_info)\n",
    "    title = extract(title_info)\n",
    "    pages = extract(pages_info).split('-')\n",
    "    output = {\n",
    "        \"authors\": authors.strip().strip(':').split(', '),\n",
    "        \"title\": title.strip(),\n",
    "        \"startPage\": int(pages[0]),\n",
    "        \"endPage\": int(pages[1])\n",
    "    }\n",
    "    return output\n",
    "\n",
    "track_candidate = [\"Research Track Full Papers\", \"Applied Data Track Full Papers\"]\n",
    "track_obj = []\n",
    "\n",
    "forward_authors = []  # For Task 5\n",
    "\n",
    "for i in range(len(track_name)):\n",
    "    if track_name[i] in track_candidate:\n",
    "        track_info = track_part[i]\n",
    "        papers_info = track_info.split('<li class=\"entry inproceedings\"')[1:]\n",
    "        papers_info = [info.split('<cite class=\"data tts-content\" itemprop=\"headline\">')[1] for info in papers_info]\n",
    "        papers = [sep_paper(paper) for paper in papers_info]\n",
    "        print(len(papers))\n",
    "        track_obj.append({\"track\": track_name[i], \"papers\": papers})\n",
    "\n",
    "        forward_authors.extend(papers_info[:10])  # For Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4\n",
    "import json\n",
    "track_str = json.dumps(track_obj, indent=2)\n",
    "with open(\"kdd23.json\", \"w\", encoding=\"UTF-8\") as file:\n",
    "    file.write(track_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5\n",
    "authors_info = \"\".join(forward_authors).split('<a href=\"')[1:]\n",
    "authors_urls = [author.split('\" itemprop=\"url\">')[0] for author in authors_info]\n",
    "authors_urls = list(set(authors_urls))\n",
    "researchers_obj = []\n",
    "\n",
    "def sep_paper_new(text, year):\n",
    "    coauthor_info, title_info = text.split('<span class=\"title\" itemprop=\"name\">')\n",
    "    title_info, *pub_info = title_info.split('</span>')\n",
    "    pub_info = ''.join(pub_info).split('</cite>')[0]\n",
    "    coauthors = extract(coauthor_info).strip().strip(':').split(', ')\n",
    "    title = extract(title_info)\n",
    "    pub = extract(pub_info).strip().strip('[content]')\n",
    "\n",
    "    output = {\n",
    "        \"authors\": coauthors,\n",
    "        \"title\": title,\n",
    "        \"publishInfo\": pub,\n",
    "        \"year\": int(year),\n",
    "    }\n",
    "    return output\n",
    "\n",
    "for i in range(len(authors_urls)):\n",
    "    print(f\"{i+1}/{len(authors_urls)}\")\n",
    "\n",
    "    author_url = authors_urls[i]\n",
    "    author_html = urlopen(url=author_url)\n",
    "    author_text = bytes.decode(author_html.read())\n",
    "\n",
    "    author_info = author_text.split('<span class=\"name primary\" itemprop=\"name\">')[1]\n",
    "    researcher = author_info.split('<')[0].strip('\"').strip()\n",
    "\n",
    "    try:\n",
    "        orcID_info = author_info.split('<li class=\"orcid drop-down\">')[1]\n",
    "        orcID_info = orcID_info.split('</div>')[0]\n",
    "        orcIDs = orcID_info.split('https://orcid.org/')[1:]\n",
    "        orcID = ','.join([piece.split('\">')[0] for piece in orcIDs])\n",
    "    except Exception:\n",
    "        orcID = ''\n",
    "\n",
    "    papers_text = author_text.split('today</h2>')[1]\n",
    "    papers_text = papers_text.split('</header>')[1]\n",
    "\n",
    "    papers_years_info = papers_text.split('<li class=\"year\">')[1:]\n",
    "    papers_years = [year_info.split('</li>')[0] for year_info in papers_years_info]\n",
    "\n",
    "    papers = []\n",
    "    for j in range(len(papers_years)):\n",
    "        papers_info = papers_years_info[j]\n",
    "        papers_year = papers_years[j]\n",
    "        papers_info = papers_info.split('<cite class=\"data tts-content\" itemprop=\"headline\">')[1:]\n",
    "        papers.extend([sep_paper_new(paper, papers_year) for paper in papers_info])\n",
    "    \n",
    "    output_dict = {\n",
    "        \"researcher\": researcher,\n",
    "        \"orcID\": orcID,\n",
    "        \"papers\": papers\n",
    "    }\n",
    "    researchers_obj.append(output_dict)\n",
    "\n",
    "researchers_str = json.dumps(researchers_obj, indent=2)\n",
    "with open(\"researchers.json\", \"w\", encoding=\"UTF-8\") as file:\n",
    "    file.write(researchers_str)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
