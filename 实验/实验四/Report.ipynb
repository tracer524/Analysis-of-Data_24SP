{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验四"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "崔士强 PB22151743"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "['node-caps', 'breast-quad']\n"
     ]
    }
   ],
   "source": [
    "columns_with_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "# Print the column names with missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(columns_with_missing_values)\n",
    "\n",
    "# Remove the rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value distribution for 'tumor-size' before corrections:\n",
      "tumor-size\n",
      "30-34     57\n",
      "25-29     51\n",
      "20-24     48\n",
      "15-19     29\n",
      "14-Oct    28\n",
      "40-44     22\n",
      "35-39     19\n",
      "0-4        8\n",
      "50-54      8\n",
      "9-May      4\n",
      "45-49      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value distribution for 'inv-nodes' before corrections:\n",
      "inv-nodes\n",
      "0-2       209\n",
      "5-Mar      34\n",
      "8-Jun      17\n",
      "11-Sep      7\n",
      "15-17       6\n",
      "14-Dec      3\n",
      "24-26       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Corrected value distribution for 'tumor-size':\n",
      "tumor-size\n",
      "30-34    57\n",
      "25-29    51\n",
      "20-24    48\n",
      "15-19    29\n",
      "10-14    28\n",
      "40-44    22\n",
      "35-39    19\n",
      "0-4       8\n",
      "50-54     8\n",
      "5-9       4\n",
      "45-49     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Corrected value distribution for 'inv-nodes':\n",
      "inv-nodes\n",
      "0-2      209\n",
      "3-5       34\n",
      "6-8       17\n",
      "9-11       7\n",
      "15-17      6\n",
      "12-14      3\n",
      "24-26      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Value distribution for 'tumor-size' before corrections:\")\n",
    "print(df['tumor-size'].value_counts())\n",
    "\n",
    "print(\"\\nValue distribution for 'inv-nodes' before corrections:\")\n",
    "print(df['inv-nodes'].value_counts())\n",
    "\n",
    "# Define a correction mapping for date-like entries\n",
    "correction_map_tumor_size = {\n",
    "    '14-Oct' : '10-14',\n",
    "    '9-May' : '5-9'\n",
    "}\n",
    "\n",
    "correction_map_inv_nodes = {\n",
    "    '5-Mar' : '3-5',\n",
    "    '8-Jun' : '6-8',\n",
    "    '11-Sep' : '9-11',\n",
    "    '14-Dec' : '12-14'\n",
    "}\n",
    "\n",
    "# Apply corrections\n",
    "df['tumor-size'] = df['tumor-size'].replace(correction_map_tumor_size)\n",
    "df['inv-nodes'] = df['inv-nodes'].replace(correction_map_inv_nodes)\n",
    "\n",
    "# Verify the corrections\n",
    "print(\"\\nCorrected value distribution for 'tumor-size':\")\n",
    "print(df['tumor-size'].value_counts())\n",
    "\n",
    "print(\"\\nCorrected value distribution for 'inv-nodes':\")\n",
    "print(df['inv-nodes'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Class=no-recurrence-events\n",
      "1 Class=recurrence-events\n",
      "2 age=10-19\n",
      "3 age=20-29\n",
      "4 age=30-39\n",
      "5 age=40-49\n",
      "6 age=50-59\n",
      "7 age=60-69\n",
      "8 age=70-79\n",
      "9 age=80-89\n",
      "10 age=90-99\n",
      "11 menopause=lt40\n",
      "12 menopause=ge40\n",
      "13 menopause=premeno\n",
      "14 tumor-size=0-4\n",
      "15 tumor-size=5-9\n",
      "16 tumor-size=10-14\n",
      "17 tumor-size=15-19\n",
      "18 tumor-size=20-24\n",
      "19 tumor-size=25-29\n",
      "20 tumor-size=30-34\n",
      "21 tumor-size=35-39\n",
      "22 tumor-size=40-44\n",
      "23 tumor-size=45-49\n",
      "24 tumor-size=50-54\n",
      "25 tumor-size=55-59\n",
      "26 inv-nodes=0-2\n",
      "27 inv-nodes=3-5\n",
      "28 inv-nodes=6-8\n",
      "29 inv-nodes=9-11\n",
      "30 inv-nodes=12-14\n",
      "31 inv-nodes=15-17\n",
      "32 inv-nodes=18-20\n",
      "33 inv-nodes=21-23\n",
      "34 inv-nodes=24-26\n",
      "35 inv-nodes=27-29\n",
      "36 inv-nodes=30-32\n",
      "37 inv-nodes=33-35\n",
      "38 inv-nodes=36-39\n",
      "39 node-caps=yes\n",
      "40 node-caps=no\n",
      "41 deg-malig=1\n",
      "42 deg-malig=2\n",
      "43 deg-malig=3\n",
      "44 breast=left\n",
      "45 breast=right\n",
      "46 breast-quad=left_up\n",
      "47 breast-quad=left_low\n",
      "48 breast-quad=right_up\n",
      "49 breast-quad=right_low\n",
      "50 breast-quad=central\n",
      "51 irradiat=yes\n",
      "52 irradiat=no\n"
     ]
    }
   ],
   "source": [
    "# 加载Excel文件\n",
    "variables_df = pd.read_excel('variables.xlsx')\n",
    "\n",
    "ind2val = {}\n",
    "current_index = 0\n",
    "\n",
    "# 对每个变量的每个值进行遍历并分配索引\n",
    "for i, row in variables_df.iterrows():\n",
    "    variable_name = row['Variable Name']\n",
    "    values = row['Description'].split(', ')\n",
    "    for value in values:\n",
    "        ind2val[current_index] = f\"{variable_name}={value}\"\n",
    "        current_index += 1\n",
    "\n",
    "# 创建从值到索引的逆映射字典\n",
    "val2ind = {v: k for k, v in ind2val.items()}\n",
    "\n",
    "# 替换数据集中的文本属性\n",
    "for column in df.columns:\n",
    "    if column in variables_df['Variable Name'].values:\n",
    "        # 为每个列值构建一个映射函数\n",
    "        df[column] = df[column].apply(lambda x: val2ind[f\"{column}={x}\"])\n",
    "\n",
    "# 打印ind2val字典\n",
    "for key in list(ind2val.keys()):\n",
    "    print(key, ind2val[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务二"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "频繁项集: [('Class', 0)], 支持度: 0.7075812274368231\n",
      "频繁项集: [('menopause', 13)], 支持度: 0.5379061371841155\n",
      "频繁项集: [('menopause', 12)], 支持度: 0.44404332129963897\n",
      "频繁项集: [('inv-nodes', 26)], 支持度: 0.7545126353790613\n",
      "频繁项集: [('node-caps', 40)], 支持度: 0.7978339350180506\n",
      "频繁项集: [('deg-malig', 42)], 支持度: 0.4657039711191336\n",
      "频繁项集: [('breast', 44)], 支持度: 0.5234657039711191\n",
      "频繁项集: [('breast', 45)], 支持度: 0.47653429602888087\n",
      "频繁项集: [('irradiat', 52)], 支持度: 0.776173285198556\n",
      "频繁项集: [('Class', 0), ('inv-nodes', 26)], 支持度: 0.5992779783393501\n",
      "频繁项集: [('Class', 0), ('node-caps', 40)], 支持度: 0.6173285198555957\n",
      "频繁项集: [('Class', 0), ('irradiat', 52)], 支持度: 0.592057761732852\n",
      "频繁项集: [('inv-nodes', 26), ('menopause', 13)], 支持度: 0.4007220216606498\n",
      "频繁项集: [('node-caps', 40), ('menopause', 13)], 支持度: 0.4223826714801444\n",
      "频繁项集: [('irradiat', 52), ('menopause', 13)], 支持度: 0.4007220216606498\n",
      "频繁项集: [('node-caps', 40), ('inv-nodes', 26)], 支持度: 0.7220216606498195\n",
      "频繁项集: [('breast', 44), ('inv-nodes', 26)], 支持度: 0.4007220216606498\n",
      "频繁项集: [('inv-nodes', 26), ('irradiat', 52)], 支持度: 0.6498194945848376\n",
      "频繁项集: [('breast', 44), ('node-caps', 40)], 支持度: 0.4151624548736462\n",
      "频繁项集: [('node-caps', 40), ('irradiat', 52)], 支持度: 0.6750902527075813\n",
      "频繁项集: [('breast', 44), ('irradiat', 52)], 支持度: 0.41155234657039713\n",
      "频繁项集: [('Class', 0), ('node-caps', 40), ('inv-nodes', 26)], 支持度: 0.5776173285198556\n",
      "频繁项集: [('Class', 0), ('inv-nodes', 26), ('irradiat', 52)], 支持度: 0.5306859205776173\n",
      "频繁项集: [('Class', 0), ('node-caps', 40), ('irradiat', 52)], 支持度: 0.5451263537906137\n",
      "频繁项集: [('Class', 0), ('inv-nodes', 26), ('node-caps', 40)], 支持度: 0.5776173285198556\n",
      "频繁项集: [('inv-nodes', 26), ('node-caps', 40), ('irradiat', 52)], 支持度: 0.6353790613718412\n",
      "频繁项集: [('node-caps', 40), ('inv-nodes', 26), ('irradiat', 52)], 支持度: 0.6353790613718412\n",
      "频繁项集: [('node-caps', 40), ('irradiat', 52), ('Class', 0), ('inv-nodes', 26)], 支持度: 0.5234657039711191\n"
     ]
    }
   ],
   "source": [
    "# 设置支持度阈值\n",
    "min_support = 0.4\n",
    "\n",
    "# 计算支持度\n",
    "def calculate_support(df, itemset):\n",
    "    mask = np.ones(len(df), dtype=bool)\n",
    "    for item in itemset:\n",
    "        mask = mask & (df[item[0]] == item[1])\n",
    "    return mask.sum() / len(df)\n",
    "\n",
    "# 生成初始单项集\n",
    "def generate_initial_itemsets(df):\n",
    "    itemsets = []\n",
    "    for col in df.columns:\n",
    "        if col != 'id':\n",
    "            unique_values = df[col].unique()\n",
    "            for val in unique_values:\n",
    "                itemsets.append([(col, val)])\n",
    "    return itemsets\n",
    "\n",
    "# 合并项集\n",
    "def merge_itemsets(itemset1, itemset2):\n",
    "    return list(set(itemset1).union(set(itemset2)))\n",
    "\n",
    "# 生成候选项集\n",
    "def generate_candidates(itemsets, length):\n",
    "    candidates = []\n",
    "    for i in range(len(itemsets)):\n",
    "        for j in range(i+1, len(itemsets)):\n",
    "            if len(set(itemsets[i]).intersection(set(itemsets[j]))) == length - 2:\n",
    "                candidate = merge_itemsets(itemsets[i], itemsets[j])\n",
    "                if len(candidate) == length:\n",
    "                    candidates.append(candidate)\n",
    "    return candidates\n",
    "\n",
    "# 生成所有组合\n",
    "def generate_combinations(items, length):\n",
    "    if length == 0:\n",
    "        return [[]]\n",
    "    combinations = []\n",
    "    for i in range(len(items)):\n",
    "        head = items[i]\n",
    "        for tail in generate_combinations(items[i + 1:], length - 1):\n",
    "            combinations.append([head] + tail)\n",
    "    return combinations\n",
    "\n",
    "# Apriori算法\n",
    "def apriori(df, min_support):\n",
    "    freq_itemsets = []\n",
    "    itemsets = generate_initial_itemsets(df)\n",
    "    k = 1\n",
    "\n",
    "    while itemsets:\n",
    "        freq_itemsets_k = []\n",
    "        for itemset in itemsets:\n",
    "            support = calculate_support(df, itemset)\n",
    "            if support >= min_support:\n",
    "                freq_itemsets_k.append(itemset)\n",
    "        freq_itemsets.extend(freq_itemsets_k)\n",
    "        itemsets = generate_candidates(freq_itemsets_k, k+1)\n",
    "        k += 1\n",
    "\n",
    "    return pd.Series(freq_itemsets).drop_duplicates().tolist()\n",
    "\n",
    "# 运行Apriori算法\n",
    "frequent_itemsets = apriori(df, min_support)\n",
    "\n",
    "# 输出结果\n",
    "for itemset in frequent_itemsets:\n",
    "    print(f\"频繁项集: {itemset}, 支持度: {calculate_support(df, itemset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "规则: [('inv-nodes', 26)] -> ('Class', 0), 置信度: 0.7942583732057417, 提升度: 1.1224978029489308\n",
      "规则: [('node-caps', 40)] -> ('Class', 0), 置信度: 0.7737556561085973, 提升度: 1.0935220241942933\n",
      "规则: [('irradiat', 52)] -> ('Class', 0), 置信度: 0.7627906976744185, 提升度: 1.0780256288561936\n",
      "规则: [('node-caps', 40), ('inv-nodes', 26)] -> ('Class', 0), 置信度: 0.7999999999999999, 提升度: 1.1306122448979592\n",
      "规则: [('inv-nodes', 26), ('irradiat', 52)] -> ('Class', 0), 置信度: 0.8166666666666667, 提升度: 1.1541666666666668\n",
      "规则: [('node-caps', 40), ('irradiat', 52)] -> ('Class', 0), 置信度: 0.8074866310160427, 提升度: 1.1411928407726726\n",
      "规则: [('inv-nodes', 26), ('node-caps', 40)] -> ('Class', 0), 置信度: 0.7999999999999999, 提升度: 1.1306122448979592\n",
      "规则: [('node-caps', 40), ('irradiat', 52), ('inv-nodes', 26)] -> ('Class', 0), 置信度: 0.8238636363636364, 提升度: 1.1643378942486085\n"
     ]
    }
   ],
   "source": [
    "# 最小置信度阈值\n",
    "min_confidence = 0.75\n",
    "\n",
    "# 计算支持度\n",
    "def calculate_support(df, itemset):\n",
    "    mask = np.ones(len(df), dtype=bool)\n",
    "    for item in itemset:\n",
    "        mask = mask & (df[item[0]] == item[1])\n",
    "    return mask.sum() / len(df)\n",
    "\n",
    "# 计算置信度\n",
    "def calculate_confidence(df, antecedent, consequent):\n",
    "    support_antecedent = calculate_support(df, antecedent)\n",
    "    support_antecedent_consequent = calculate_support(df, antecedent + consequent)\n",
    "    return support_antecedent_consequent / support_antecedent\n",
    "\n",
    "# 计算提升度\n",
    "def calculate_lift(df, antecedent, consequent):\n",
    "    support_antecedent_consequent = calculate_support(df, antecedent + consequent)\n",
    "    support_antecedent = calculate_support(df, antecedent)\n",
    "    support_consequent = calculate_support(df, consequent)\n",
    "    return support_antecedent_consequent / (support_antecedent * support_consequent)\n",
    "\n",
    "# 提取强关联规则\n",
    "def extract_strong_rules(df, frequent_itemsets, min_confidence):\n",
    "    strong_rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "        if ('Class', 0) not in itemset:\n",
    "            continue\n",
    "        antecedents = [x for x in itemset if x != ('Class', 0)]\n",
    "        if antecedents:\n",
    "            confidence = calculate_confidence(df, antecedents, [('Class', 0)])\n",
    "            if confidence >= min_confidence:\n",
    "                lift = calculate_lift(df, antecedents, [('Class', 0)])\n",
    "                strong_rules.append((antecedents, ('Class', 0), confidence, lift))\n",
    "    return pd.Series(strong_rules).drop_duplicates().tolist()\n",
    "\n",
    "strong_rules = extract_strong_rules(df, frequent_itemsets, min_confidence)\n",
    "\n",
    "# 输出结果\n",
    "for antecedents, consequent, confidence, lift in strong_rules:\n",
    "    print(f\"规则: {antecedents} -> {consequent}, 置信度: {confidence}, 提升度: {lift}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从频繁项集来看，无结节冒，未采取放疗，受侵淋巴结数目在0-2，疾病没有复发这些特征为数据集中较为常见的。\n",
    "\n",
    "将提取出的关联规则替换为原本的文字得到如下结果：\n",
    "1. inv-nodes=0-2 -> Class=no-recurrence-events\n",
    "2. node-caps=no -> Class=no-recurrence-events\n",
    "3. irradiat=no -> Class=no-recurrence-events\n",
    "4. node-caps=no, inv-nodes=0-2 -> Class=no-recurrence-events\n",
    "5. inv-nodes=0-2, irradiat=no -> Class=no-recurrence-events\n",
    "6. node-caps=no, irradiat=no -> Class=no-recurrence-events\n",
    "7. inv-nodes=0-2, node-caps=no -> Class=no-recurrence-events\n",
    "8. node-caps=no, irradiat=no, inv-nodes=0-2 -> Class=no-recurrence-events\n",
    "\n",
    "由上面的结果可以得到：无结节冒，未采取放疗，受侵淋巴结数目在0-2这些特征存在的情况下，不复发的概率较高。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
